---
title: "IB031 - Project"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

## Popis datasetu
Dataset, který jsem si zvolil klasifikuje bílá a červená vína podle jejich kvality na základě atributů: kyselost, cukernatost, obsah síry, hustota, pH a obsah alkoholu.
Dataset obsahuje celkem 6497 vín. 
## Nahrání dat a knihoven

```{r data.wine}
library(RWeka)

wine.all <- read.csv("winequalityN.csv")

```

## Explorační analýza

Dataset obsahuje celkem 6497 vín, z toho je 1599 červených a 4898 bílých. 7 z 13 atributů obsahují nějaké chybějící hodnoty. 

```{r analysis.wine}
head(wine.all)
tail(wine.all)
summary(wine.all)
```

Zajímavé je rozložení hodnot atributu quality, která připomíná graf normálního rozložení. 

```{r}
wine.all$quality <- as.factor(wine.all$quality)
plot(wine.all$quality)

```

Nepřekvapivé je zjištění, že červená vína nejsou tak sladká jak bílé, a naopak bílé dosahují daleko nižší kyselosti.

```{r}
plot(wine.all$fixed.acidity, wine.all$residual.sugar, col = wine.all$type)
legend("topright", levels(wine.all$type), col = 1:2, pch = 20, title = "Wines")
```

Jde také vidět že kvalitnější vína mají obvykle vyšší obsah alkoholu.

```{r}
plot(wine.all$quality, wine.all$alcohol)
```

## Baseline model

Jako první jsem se pokusil natrénovat model bez jakéhokoliv předzpracování. Výseldek dopadl nevalně, přesnost byla bohužel jen něco přes 33%.

```{r}
wine.all$quality <- as.factor(wine.all$quality)
wine.train <- wine.all[1:3248, ]
wine.test <- wine.all[3249:6497, ]

### raw model without any preprocessing and tuning
model.wine.raw <- J48(quality ~ ., data = wine.train)
prediction.wine.raw <- predict(model.wine.raw, newdata = wine.test)
references.wine.raw <- wine.test$quality

confmat.wine.raw <- table(prediction.wine.raw, references.wine.raw)
accuracy.wine.raw <- sum(diag(confmat.wine.raw)) / sum(confmat.wine.raw)
accuracy.wine.raw
```
## Předzpracování

Je nutné změnit cílovou třídu na factor. Dále je třeba se vypořádat s chybějícími hodnotami, vzhledem k tomu, že všechny atributy kde se chybějící hodnoty nacházejí jsou číselné, rozhodl jsem se k nahrazení chybějících hodnot hodnotou průměrnou. Dále jsem všechny vína z kategorií kvality 3 a 9 přesunul do kategorií 4 resp. 8, jelikož těchto vín bylo velmi málo a negativně tyto položky ovlivňovaly přesnost modelu. Jako poslední jsem data náhodně promíchal a rozdělil na poloviny na trénovací a testovací množinu.

```{r}

## removing missing values

wine.all[is.na(wine.all$fixed.acidity), "fixed.acidity"] <- mean(wine.all$fixed.acidity, na.rm = T)
wine.all[is.na(wine.all$volatile.acidity), "volatile.acidity"] <- mean(wine.all$volatile.acidity, na.rm = T)
wine.all[is.na(wine.all$citric.acid), "citric.acid"] <- mean(wine.all$citric.acid, na.rm = T)
wine.all[is.na(wine.all$residual.sugar), "residual.sugar"] <- mean(wine.all$residual.sugar, na.rm = T)
wine.all[is.na(wine.all$chlorides), "chlorides"] <- mean(wine.all$chlorides, na.rm = T)
wine.all[is.na(wine.all$pH), "pH"] <- mean(wine.all$pH, na.rm = T)
wine.all[is.na(wine.all$sulphates), "sulphates"] <- mean(wine.all$sulphates, na.rm = T)

## merging category no.3 to no.4 and no.9 to no.8
wine.all[(wine.all$quality == 3), "quality"] <- 4
wine.all[(wine.all$quality == 9), "quality"] <- 8
wine.all$quality <- droplevels(wine.all$quality, exclude = c(3,9))

wine.all$quality <- as.factor(wine.all$quality)

##data shufling
wine.all <- wine.all[sample(nrow(wine.all)), ] 

wine.train <- wine.all[1:((nrow(wine.all)) * 0.7), ]
wine.test <- wine.all[(nrow(wine.all)*0.7):nrow(wine.all), ]
```

## Model C4.5

Na natrénování tohoto modelu jsem použil algoritmus C4.5, v jazyce R implementovaný v knihovně RWeka a také v knihovně caret. Já použil implementaci z knihovny RWeka, kde je tento algoritmus implementovaný funkcí "J48". Algoritmus C4.5 vychází ze staršího algoritmu ID3, a tento algoritmus dále rozšiřuje. Používá se ke klasifikaci a tvorbě rozhodovacích klasifikačních stromů. 
Princip jeho funkce je následující:
Spočte informační zisk jednotlivých atributů tak, aby co nejlépe rozdělovali danou množinu. Tento atribut se poté umístí do daného uzlu, který rozhoduje podle atributu s největším informačním ziskem a rekurzivně se pokračuje na podmnožinách daných rozdělením na předchozím uzlu.
```{r}
model.wine <- J48(quality ~ ., data = wine.train, control = Weka_control(R = F, M = 1))
prediction.wine <- predict(model.wine, wine.test)
```

## Vyhodnocení modelu

```{r}

references.wine <- wine.test$quality

confmat.wine <- table(prediction.wine, references.wine)
confmat.wine


accuracy.wine <- sum(diag(confmat.wine)) / sum(confmat.wine)
accuracy.wine
```

Bohužel model se nepodařilo natrénovat na více než něco kolem 58%. Není to mnoho, je však třeba brát v úvahu několik věcí. Jednak hodnocení kvality je subjektivní záležitost, a nelze ji jednoznačně odhadnout. Druhou věcí je fakt, že naprostá většina chybných klasifikací probíhá pouze o jednu třídu, ať už výš nebo níž. Po zvážení tohoto faktu jsem mírně upravil výpočet přesnosti tak, aby se za správný odhad považovalo pokud je víno zařazeno do správné kategorie nebo nanejvýš o jednu kategorii vedle. S touto tolerancí již přesnost dosahuje zhruba 93%, je proto zřejmé, že většina chybných klasifikací je pouze o jednu třídu.

```{r}

### evaluation with toleration +- 1 class
accuracy.wine.with.tolerance <- confmat.wine[1:1] + confmat.wine[1,2]
for(i in 2:4){
  for(j in (i-1):(i+1)){
    accuracy.wine.with.tolerance <- accuracy.wine.with.tolerance + confmat.wine[i,j]
  }
}
accuracy.wine.with.tolerance <- accuracy.wine.with.tolerance + confmat.wine[5,4] + confmat.wine[5,5]
accuracy.wine.with.tolerance <- accuracy.wine.with.tolerance / sum(confmat.wine)
accuracy.wine.with.tolerance
```

Tento model se tedy při použití na tomto konkrétním datasetu příliš neosvědčil. Je to dáno pravděpodobně větším množstvím možných výsledných klasifikací mezi kterými nelze přesně rozhodnout na základě daných atributů. V ostatních použitých modelech dopadly výsledky lépe, byť ne o mnoho. V algoritmu Random Forest byla přesnost okolo 70% a při algoritmu ID3 se pohybovala kolem 65%.

## Dataset mushrooms

## Explorační analýza

Tento dataset obsahuje 8124 položek a rozhoduje zda je houba jedovatá či nikoliv. Velikost množin jedovatých a jedlých hub je téměř stejná, žádné atributy neobsahují chybějící hodnoty. Z tohoto důvodu nebyla nutná prakticky žádná úprava ani žádné parametry modelu aby se dosáhlo přesnosti téměř 100%.

```{r}
####### loading data #######
library(RWeka)
mushrooms.all <- read.csv("mushrooms.csv")
######## analysis ########
head(mushrooms.all)
summary(mushrooms.all)
###### preprocessing ########
mushrooms.all <- mushrooms.all[sample(nrow(mushrooms.all)), ]
mushrooms.train <- mushrooms.all[1:4062, ]
mushrooms.test <- mushrooms.all[4063:8124, ]
##### model #####
model.mushrooms <- J48(class ~ ., mushrooms.train, control = Weka_control(R = T))
prediction.mushrooms <- predict(model.mushrooms, mushrooms.test)
references.mushrooms <- mushrooms.test$class
confmat.mushrooms <- table(prediction.mushrooms, references.mushrooms)
confmat.mushrooms
accuracy.mushrooms <- sum(diag(confmat.mushrooms)) / sum(confmat.mushrooms)
accuracy.mushrooms
```


## Dataset cars


```{r}
######## loading data #######
library(RWeka)
cars.all <- read.csv("car.data")
names(cars.all) <- c("buying", "maint", "doors", "persons", "lug_boot", "safety", "class")
head(cars.all)
summary(cars.all)
```


```{r}
cars.all <- cars.all[sample(nrow(cars.all)), ]
cars.train <- cars.all[1:(nrow(cars.all)*0.7), ]
cars.test <- cars.all[(nrow(cars.all)*0.7):nrow(cars.all), ]
model.cars <- J48(class ~ ., cars.train, control = Weka_control(R = T, M = 1))
prediction.cars <- predict(model.cars, cars.test)
references.cars <- cars.test$class
confmat <- table(prediction.cars, references.cars)
confmat
```

```{r}
accuracy.cars <- sum(diag(confmat)) / sum(confmat)
accuracy.cars
```
