---
title: "IB031 - Project"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

## Popis datasetu
Dataset, který jsem si zvolil klasifikuje bílá a červená vína podle jejich kvality na základě atributů: kyselost, cukernatost, obsah síry, hustota, pH a obsah alkoholu.
Dataset obsahuje celkem 6497 vín.

## Nahrání dat a knihoven

```{r data.wine}
library(RWeka)

wine.all <- read.csv("winequalityN.csv")

```

## Explorační analýza

Dataset obsahuje celkem 6497 vín, z toho je 1599 červených a 4898 bílých. 7 z 13 atributů obsahují nějaké chybějící hodnoty. 

```{r analysis.wine}
head(wine.all)
tail(wine.all)
summary(wine.all)
```

Zajímavé je rozložení hodnot atributu quality - připomíná graf normálního rozložení. 

```{r}
wine.all$quality <- as.factor(wine.all$quality)
plot(wine.all$quality)

```

Nepřekvapivé je zjištění, že červená vína nejsou tak sladká jak bílé, a naopak bílé dosahují daleko nižší kyselosti.

```{r}
plot(wine.all$fixed.acidity, wine.all$residual.sugar, col = wine.all$type)
legend("topright", levels(wine.all$type), col = 1:2, pch = 20, title = "Wines")
```

Jde také vidět že kvalitnější vína mají obvykle vyšší obsah alkoholu.

```{r}
plot(wine.all$quality, wine.all$alcohol)
```

## Baseline model

Jako první jsem se pokusil natrénovat model bez jakéhokoliv předzpracování. Výseldek dopadl nevalně, přesnost byla bohužel jen něco přes 33%.

```{r}
wine.all$quality <- as.factor(wine.all$quality)
wine.train <- wine.all[1:((nrow(wine.all)) * 0.7), ]
wine.test <- wine.all[(nrow(wine.all)*0.7):nrow(wine.all), ]

### raw model without any preprocessing and tuning
model.wine.raw <- J48(quality ~ ., data = wine.train)
prediction.wine.raw <- predict(model.wine.raw, newdata = wine.test)
references.wine.raw <- wine.test$quality

confmat.wine.raw <- table(prediction.wine.raw, references.wine.raw)
accuracy.wine.raw <- sum(diag(confmat.wine.raw)) / sum(confmat.wine.raw)
accuracy.wine.raw
```
## Předzpracování

Bylo nutné změnit cílovou třídu na factor. Dále je třeba se vypořádat s chybějícími hodnotami, vzhledem k tomu, že všechny atributy kde se chybějící hodnoty nacházejí jsou číselné, rozhodl jsem se k nahrazení chybějících hodnot hodnotou průměrnou. Dále jsem všechny vína z kategorií kvality 3 a 9 přesunul do kategorií 4 resp. 8, jelikož těchto vín bylo velmi málo a tyto položky negativně ovlivňovaly přesnost modelu. Jako poslední jsem data náhodně promíchal a rozdělil na trénovací a testovací množinu v poměru 7 ku 3.

```{r}

## removing missing values

wine.all[is.na(wine.all$fixed.acidity), "fixed.acidity"] <- mean(wine.all$fixed.acidity, na.rm = T)
wine.all[is.na(wine.all$volatile.acidity), "volatile.acidity"] <- mean(wine.all$volatile.acidity, na.rm = T)
wine.all[is.na(wine.all$citric.acid), "citric.acid"] <- mean(wine.all$citric.acid, na.rm = T)
wine.all[is.na(wine.all$residual.sugar), "residual.sugar"] <- mean(wine.all$residual.sugar, na.rm = T)
wine.all[is.na(wine.all$chlorides), "chlorides"] <- mean(wine.all$chlorides, na.rm = T)
wine.all[is.na(wine.all$pH), "pH"] <- mean(wine.all$pH, na.rm = T)
wine.all[is.na(wine.all$sulphates), "sulphates"] <- mean(wine.all$sulphates, na.rm = T)

## merging category no.3 to no.4 and no.9 to no.8
wine.all[(wine.all$quality == 3), "quality"] <- 4
wine.all[(wine.all$quality == 9), "quality"] <- 8
wine.all$quality <- droplevels(wine.all$quality, exclude = c(3,9))

wine.all$quality <- as.factor(wine.all$quality)

##data shufling
wine.all <- wine.all[sample(nrow(wine.all)), ] 

wine.train <- wine.all[1:((nrow(wine.all)) * 0.7), ]
wine.test <- wine.all[(nrow(wine.all)*0.7):nrow(wine.all), ]
```

## Model C4.5

Na natrénování tohoto modelu jsem použil algoritmus C4.5, v jazyce R implementovaný v knihovně RWeka a také v knihovně caret. Já použil implementaci z knihovny RWeka, kde je tento algoritmus implementovaný funkcí "J48". Algoritmus C4.5 vychází ze staršího algoritmu ID3, a tento algoritmus dále rozšiřuje. Používá se ke klasifikaci a tvorbě rozhodovacích klasifikačních stromů. 
Princip jeho funkce je následující:
Spočte informační zisk jednotlivých atributů tak, aby co nejlépe rozdělovali danou množinu. Tento atribut se poté umístí do daného uzlu, který rozhoduje podle atributu s největším informačním ziskem a rekurzivně se pokračuje na podmnožinách daných rozdělením na předchozím uzlu.

## Modely s různými parametry

## Model 1
```{r}
model.wine.1 <- J48(quality ~ ., data = wine.train, control = Weka_control(R = F, M = 1))
prediction.wine.1 <- predict(model.wine.1, wine.test)
```

## Vyhodnocení modelu 1

```{r}

references.wine <- wine.test$quality

confmat.wine.1 <- table(prediction.wine.1, references.wine)
confmat.wine.1


accuracy.wine.1 <- sum(diag(confmat.wine.1)) / sum(confmat.wine.1)
accuracy.wine.1
```


## Model 2
```{r}
model.wine.2 <- J48(quality ~ ., data = wine.train, control = Weka_control(R = T, M = 50, A = T))
prediction.wine.2 <- predict(model.wine.2, wine.test)
```

## Vyhodnocení modelu 2

```{r}

confmat.wine.2 <- table(prediction.wine.2, references.wine)
confmat.wine.2


accuracy.wine.2 <- sum(diag(confmat.wine.2)) / sum(confmat.wine.2)
accuracy.wine.2
```

## Model 3
```{r}
model.wine.3 <- J48(quality ~ ., data = wine.train, control = Weka_control(M = 200))
prediction.wine.3 <- predict(model.wine.3, wine.test)
```

## Vyhodnocení modelu 3

```{r}

confmat.wine.3 <- table(prediction.wine.3, references.wine)
confmat.wine.3


accuracy.wine.3 <- sum(diag(confmat.wine.3)) / sum(confmat.wine.3)
accuracy.wine.3
```

## Vyhodnocení modelu 
Výrazně nejlepší je konfigurace parametrů v případě č.1 kdy dosahuje přesnost něco kolem 58% což je výrazně více než zbylé dva a rovněž než základní testovací model, který dosáhl přesnosti cca. 33%.
Bohužel model se nepodařilo natrénovat na více než 58%. Není to mnoho, je však třeba brát v úvahu několik věcí. Jednak hodnocení kvality je subjektivní záležitost, a nelze ji jednoznačně odhadnout. Druhou věcí je fakt, že naprostá většina chybných klasifikací probíhá pouze o jednu třídu, ať už výš nebo níž. Po zvážení tohoto faktu jsem mírně upravil výpočet přesnosti tak, aby se za správný odhad považovalo pokud je víno zařazeno do správné kategorie nebo nanejvýš o jednu kategorii vedle. S touto tolerancí již přesnost dosahuje zhruba 93%, je proto zřejmé, že většina chybných klasifikací je pouze o jednu třídu.

```{r}

# evaluation with toleration +- 1 class
accuracy.wine.with.tolerance <- confmat.wine.1[1:1] + confmat.wine.1[1,2]
for(i in 2:4){
  for(j in (i-1):(i+1)){
    accuracy.wine.with.tolerance <- accuracy.wine.with.tolerance + confmat.wine.1[i,j]
  }
}
accuracy.wine.with.tolerance <- accuracy.wine.with.tolerance + confmat.wine.1[5,4] + confmat.wine.1[5,5]
accuracy.wine.with.tolerance <- accuracy.wine.with.tolerance / sum(confmat.wine.1)
accuracy.wine.with.tolerance
```

## Závěr
Tento model se při použití na tomto konkrétním datasetu příliš neosvědčil. Je to dáno pravděpodobně větším množstvím možných výsledných klasifikací mezi kterými nelze přesně rozhodnout na základě daných atributů. V ostatních použitých modelech dopadly výsledky lépe, byť ne o mnoho. V algoritmu Random Forest byla přesnost okolo 70% a při algoritmu ID3 se pohybovala kolem 65%.

## Dataset mushrooms

## Explorační analýza

Tento dataset obsahuje 8124 položek a rozhoduje zda je houba jedovatá či nikoliv. Velikost množin jedovatých a jedlých hub je téměř stejná, žádné atributy neobsahují chybějící hodnoty. Z tohoto důvodu nebyla nutná prakticky žádná úprava ani žádné parametry modelu aby se dosáhlo přesnosti téměř 100%.

```{r}
####### loading data #######
library(RWeka)
mushrooms.all <- read.csv("mushrooms.csv")
######## analysis ########
head(mushrooms.all)
summary(mushrooms.all)
###### preprocessing ########
mushrooms.all <- mushrooms.all[sample(nrow(mushrooms.all)), ]
mushrooms.train <- mushrooms.all[1:(nrow(mushrooms.all)*0.7), ]
mushrooms.test <- mushrooms.all[(nrow(mushrooms.all)*0.7):nrow(mushrooms.all), ]
##### model #####
model.mushrooms <- J48(class ~ ., mushrooms.train, control = Weka_control(R = T))
prediction.mushrooms <- predict(model.mushrooms, mushrooms.test)
references.mushrooms <- mushrooms.test$class
confmat.mushrooms <- table(prediction.mushrooms, references.mushrooms)
confmat.mushrooms
accuracy.mushrooms <- sum(diag(confmat.mushrooms)) / sum(confmat.mushrooms)
accuracy.mushrooms
```

## Závěr

Tento model se na konkrétní dataset hodí velmi pěkně a téměř se 100% přesností klasifikuje jednotlivé houby do správných kategorií. Je to dle mého názoru dané především tím, že tento dataset je primárně určen přesně na tyto typy úloh. Při sbírání hub bych se na něj však pravděpodobně nespoléhal. :)


## Dataset cars

Tento dataset hodnotí vozy podle jednotlivých kritérií jako nevyhovující, vyhovující, dobré a velmi dobré.

```{r}
######## loading data #######
library(RWeka)
cars.all <- read.csv("car.data")
names(cars.all) <- c("buying", "maint", "doors", "persons", "lug_boot", "safety", "class")
head(cars.all)
summary(cars.all)
```

Preprocesing a trénování modelu
```{r}
cars.all <- cars.all[sample(nrow(cars.all)), ]
cars.train <- cars.all[1:(nrow(cars.all)*0.7), ]
cars.test <- cars.all[(nrow(cars.all)*0.7):nrow(cars.all), ]
model.cars <- J48(class ~ ., cars.train, control = Weka_control(R = T, M = 1))
prediction.cars <- predict(model.cars, cars.test)
references.cars <- cars.test$class
confmat <- table(prediction.cars, references.cars)
confmat
```

```{r}
accuracy.cars <- sum(diag(confmat)) / sum(confmat)
accuracy.cars
```

Výsledná hodnota se pohybuje kolem 89%. 

## Závěr

Algoritmus J48 se velmi osvědčil při tvorbě modelu nad datasetem mushrooms, kde dosahoval 100% úspěšnosti. Na datasetu cars se maximální úspěšnost pohybovala lehce pod 90% což je dle mého názoru také dobrý výsledek. Nejhorší úspěšnost model vykazoval nad datasetem wine, zde se dosahovalo přesnosti kolem 58%, nepřesnost ale  byla způsobena pravděpodobně velmi jemným členěním na výsledné kategorie, neboť pokud se vzala v úvahu tolerance tak úspěšnost již velmi výrazně převyšovala 90%.


## Souhrn
Úspěšnost modelů se na tomto datasetu dost značně lišila. Ze tří algoritmů byly výsledky následující: 
ID3 : ~ 65%
C4.5: ~ 58%
Random Forest: ~ 70%

Pro tento dataset se tedy zjevně modely C4.5 a ID3 hodí nejméně. Je ale nutné poznamenat, že v drtivé většině se model pletl jen o jednu skupinu, což vzhledem k tomu, že skupin bylo velmi mnoho, byť byly redukovány dvě okrajové skupiny, je přijatelné. Členění bylo velmi jemné a z tohoto důvodu nebyl model schopen korektně zařadit vína do té správné skupiny. Byl dobře schopen od sebe odlišit vína vyšší a nižší kvality. Pokud jsme tedy tolerovali nepřesnost +- 1 skupina, úspěšnost již dosahovala cca 93%, což je velmi slušný výsledek. Výsledky by se tedy daly výrazně zlepšit např. sloučením několika skupin do 1, nebo čistě vína rozdělit pouze na dobrá a špatná podle toho, do jaké skupiny patří. (např. skupina 3 - 5 = nízká kvalita, 6 - 8 = vysoká kvalita).

